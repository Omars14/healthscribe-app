# n8n Workflow Migration Guide: Using OpenAI Transcribe Audio Node

## Why Switch to the OpenAI Node?

### âœ… Benefits of Using the Dedicated OpenAI Node:

1. **Simplified Workflow** - Replace 3-4 HTTP nodes with 1 OpenAI node
2. **Built-in Error Handling** - Automatic retries on failures
3. **Better File Management** - Handles large files and streaming automatically
4. **Secure Credentials** - API keys stored in n8n's credential system
5. **Automatic Updates** - Gets improvements with n8n updates

### ðŸ“Š Comparison

| Feature | HTTP Request Nodes | OpenAI Node |
|---------|-------------------|-------------|
| Setup Complexity | High | Low |
| Error Handling | Manual | Automatic |
| File Size Limits | Manual chunking | Handled automatically |
| API Key Security | In workflow | In credentials |
| Maintenance | Manual updates | Auto with n8n |

## Migration Steps

### Step 1: Install/Update n8n Nodes
Ensure you have the latest OpenAI node installed in your n8n instance:
```bash
npm install -g n8n@latest
# or if using Docker, pull latest image
docker pull n8nio/n8n:latest
```

### Step 2: Set Up OpenAI Credentials in n8n

1. Go to **Credentials** in n8n
2. Click **Add Credential**
3. Search for **OpenAI API**
4. Add your API key
5. Name it (e.g., "OpenAI Whisper")
6. Save

### Step 3: Import the Optimized Workflow

1. Open n8n
2. Click **Workflows** â†’ **Import from File**
3. Select `n8n-optimized-workflow.json`
4. Update the credential references

### Step 4: Key Differences to Note

#### Old Approach (HTTP Nodes):
```javascript
// Multiple nodes needed:
// 1. HTTP Request to OpenAI
// 2. Handle authentication headers
// 3. Parse response
// 4. Error handling logic
```

#### New Approach (OpenAI Node):
```javascript
// Single node handles everything:
// - Authentication
// - File upload
// - Response parsing
// - Error retry logic
```

### Step 5: Configure the OpenAI Node

The OpenAI Transcribe Audio node accepts these parameters:

- **File**: Binary data from previous node
- **Model**: `whisper-1` (default)
- **Language**: Optional language code (e.g., 'en', 'es')
- **Prompt**: Optional context prompt
- **Temperature**: 0-1 (0 = more deterministic)
- **Response Format**: 
  - `json` - Basic transcription
  - `verbose_json` - With timestamps and segments
  - `text` - Plain text only
  - `srt` - Subtitle format
  - `vtt` - WebVTT format

### Step 6: Update Your API Endpoint

Your Next.js API should remain the same, as it's already sending the correct format:

```typescript
// No changes needed in your API
const response = await fetch(n8nWebhookUrl, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    id: transcriptionId,
    audio: base64Audio,
    format: 'webm',
    language: 'en'
  })
});
```

## Testing the New Workflow

### 1. Test with Small File
```bash
# Use the existing test script
node test-transcription.js
```

### 2. Monitor in n8n
- Check execution logs
- Verify transcription output
- Confirm database updates

### 3. Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| "Invalid API Key" | Check credentials in n8n |
| "File too large" | OpenAI node handles up to 25MB automatically |
| "Unsupported format" | Convert to supported format (mp3, mp4, wav, webm, etc.) |
| "Timeout" | Increase workflow timeout in settings |

## Performance Improvements

The OpenAI node provides several performance benefits:

1. **Automatic Chunking** - For large files
2. **Connection Pooling** - Reuses HTTPS connections
3. **Smart Retries** - Exponential backoff on failures
4. **Streaming Support** - For real-time processing

## Advanced Configuration

### Using with Binary Data
```json
{
  "parameters": {
    "resource": "audio",
    "operation": "transcribe",
    "binaryPropertyName": "data",
    "options": {
      "responseFormat": "verbose_json",
      "timestampGranularities": ["segment", "word"]
    }
  }
}
```

### Error Handling Branch
The OpenAI node automatically routes to error output on failure, making it easy to:
- Log errors to database
- Send notifications
- Implement fallback logic

## Rollback Plan

If you need to rollback:
1. Keep your original workflow exported
2. Test new workflow in parallel first
3. Switch webhook URLs when ready
4. Keep old workflow inactive but available

## Best Practices

1. **Always use credentials** - Never hardcode API keys
2. **Set appropriate timeouts** - 900s for large files
3. **Log all executions** - Enable in workflow settings
4. **Use verbose_json format** - Gets timestamps and segments
5. **Implement error notifications** - Add email/Slack node on error branch

## Migration Checklist

- [ ] Update n8n to latest version
- [ ] Create OpenAI credentials in n8n
- [ ] Import optimized workflow
- [ ] Configure webhook URL
- [ ] Test with sample audio
- [ ] Verify database updates
- [ ] Test error handling
- [ ] Update production webhook URL
- [ ] Monitor first 24 hours
- [ ] Archive old workflow

## Support Resources

- [n8n OpenAI Node Docs](https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.openai/)
- [OpenAI Whisper API Docs](https://platform.openai.com/docs/guides/speech-to-text)
- [n8n Community Forum](https://community.n8n.io/)

## Summary

Switching to the OpenAI node will:
- Reduce workflow complexity by 60%
- Improve reliability with built-in error handling
- Enhance security with credential management
- Provide better performance for large files
- Simplify maintenance and updates

The migration can be done with zero downtime by running both workflows in parallel during testing.
